{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd07e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dce2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "\"\"\"\n",
    "In previous examples we've annotated the `messages` state key\n",
    "with the default `operator.add` or `+` reducer, which always\n",
    "appends new messages to the end of the existing messages array.\n",
    "\n",
    "Now, to support replacing existing messages, we annotate the\n",
    "`messages` key with a customer reducer function, which replaces\n",
    "messages with the same `id`, and appends them otherwise.\n",
    "\"\"\"\n",
    "def reduce_messages(left: list[AnyMessage], right: list[AnyMessage]) -> list[AnyMessage]:\n",
    "    # assign ids to messages that don't have them\n",
    "    for message in right:\n",
    "        if not message.id:\n",
    "            message.id = str(uuid4())\n",
    "    # merge the new messages with the existing messages\n",
    "    merged = left.copy()\n",
    "    for message in right:\n",
    "        for i, existing in enumerate(merged):\n",
    "            # replace any existing messages with the same id\n",
    "            if existing.id == message.id:\n",
    "                merged[i] = message\n",
    "                break\n",
    "        else:\n",
    "            # append any new messages to the end\n",
    "            merged.append(message)\n",
    "    return merged\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], reduce_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#      Manual human approval\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, tools, system=\"\", checkpointer=None):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(\n",
    "            checkpointer=checkpointer,\n",
    "            interrupt_before=[\"action\"]\n",
    "        )\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        print(state)\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03f3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63541539",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Whats the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "##continue after interrupt\n",
    "\n",
    "for event in abot.graph.stream(None, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001dbfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71b044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread).next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)\n",
    "while abot.graph.get_state(thread).next:\n",
    "    print(\"\\n\", abot.graph.get_state(thread),\"\\n\")\n",
    "    _input = input(\"proceed?\")\n",
    "    if _input != \"y\":\n",
    "        print(\"aborting\")\n",
    "        break\n",
    "    for event in abot.graph.stream(None, thread):\n",
    "        for v in event.values():\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify State Run until the interrupt and then modify the state.\n",
    "\n",
    "messages = [HumanMessage(\"Whats the weather in LA?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595ba33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5063f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_values = abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58824ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_values.values['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe97a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_values.values['messages'][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76065b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = current_values.values['messages'][-1].tool_calls[0]['id']\n",
    "current_values.values['messages'][-1].tool_calls = [\n",
    "    {'name': 'tavily_search_results_json',\n",
    "  'args': {'query': 'current weather in Louisiana'},\n",
    "  'id': _id}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.update_state(thread, current_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f2dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Time Travel Time Travel\n",
    "states = []\n",
    "for state in abot.graph.get_state_history(thread):\n",
    "    print(state)\n",
    "    print('--')\n",
    "    states.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cdaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##   To fetch the same state as was filmed, the offset below is changed to -3 from -1. This accounts for the initial state __start__ and the first state that are now stored to state memory with the latest version of software\n",
    "\n",
    "to_replay = states[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, to_replay.config):\n",
    "    for k, v in event.items():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Go back in time and edit\n",
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dcb288",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay.values['messages'][-1].tool_calls[0]['id']\n",
    "to_replay.values['messages'][-1].tool_calls = [{'name': 'tavily_search_results_json',\n",
    "  'args': {'query': 'current weather in LA, accuweather'},\n",
    "  'id': _id}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5598e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_state = abot.graph.update_state(to_replay.config, to_replay.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, branch_state):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add message to a state at a given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02531ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = to_replay.values['messages'][-1].tool_calls[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05545f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_update = {\"messages\": [ToolMessage(\n",
    "    tool_call_id=_id,\n",
    "    name=\"tavily_search_results_json\",\n",
    "    content=\"54 degree celcius\",\n",
    ")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42738b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_and_add = abot.graph.update_state(\n",
    "    to_replay.config, \n",
    "    state_update, \n",
    "    as_node=\"action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in abot.graph.stream(None, branch_and_add):\n",
    "    for k, v in event.items():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extra Practice   \n",
    "#Build a small graph This is a small simple graph you can tinker with if you want more insight into controlling state memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d727f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a simple 2 node graph with the following state: -lnode: last node -scratch: a scratchpad location -count : a counter that is incremented each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35bec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    lnode: str\n",
    "    scratch: str\n",
    "    count: Annotated[int, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42444697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node1(state: AgentState):\n",
    "    print(f\"node1, count:{state['count']}\")\n",
    "    return {\"lnode\": \"node_1\",\n",
    "            \"count\": 1,\n",
    "           }\n",
    "def node2(state: AgentState):\n",
    "    print(f\"node2, count:{state['count']}\")\n",
    "    return {\"lnode\": \"node_2\",\n",
    "            \"count\": 1,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "##The graph goes N1->N2->N1... but breaks after count reaches 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    return state[\"count\"] < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"Node1\", node1)\n",
    "builder.add_node(\"Node2\", node2)\n",
    "\n",
    "builder.add_edge(\"Node1\", \"Node2\")\n",
    "builder.add_conditional_edges(\"Node2\", \n",
    "                              should_continue, \n",
    "                              {True: \"Node1\", False: END})\n",
    "builder.set_entry_point(\"Node1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Run it!\n",
    "#Now, set the thread and run!\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": str(1)}}\n",
    "graph.invoke({\"count\":0, \"scratch\":\"hi\"},thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dab9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at current state\n",
    "#Get the current state. Note the values which are the AgentState. Note the config and the thread_ts. You will be using those to refer to snapshots below\n",
    "\n",
    "graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###View all the statesnapshots in memory. You can use the displayed count agentstate variable to help track what you see. Notice the most recent snapshots are returned by the iterator first. Also note that there is a handy step variable in the metadata that counts the number of steps in the graph execution. This is a bit detailed - but you can also notice that the parent_config is the config of the previous node. At initial startup, additional states are inserted into memory to create a parent. This is something to check when you branch or time travel below.\n",
    "\n",
    "#Look at state history\n",
    "\n",
    "for state in graph.get_state_history(thread):\n",
    "    print(state, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store just the config into an list. Note the sequence of counts on the right. get_state_history returns the most recent snapshots first.\n",
    "\n",
    "states = []\n",
    "for state in graph.get_state_history(thread):\n",
    "    states.append(state.config)\n",
    "    print(state.config, state.values['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab an early state.\n",
    "states[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the state after Node1 completed for the first time. Note next is Node2 and count is 1.\n",
    "graph.get_state(states[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6eec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go Back in Time\n",
    "#Use that state in invoke to go back in time. Notice it uses states[-3] as current_state and continues to node2,\n",
    "graph.invoke(None, states[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the new states are now in state history. Notice the counts on the far right.\n",
    "thread = {\"configurable\": {\"thread_id\": str(1)}}\n",
    "for state in graph.get_state_history(thread):\n",
    "    print(state.config, state.values['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abeed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see the details below. Lots of text, but try to find the node that start the new branch. Notice the parent config is not the previous entry in the stack, but is the entry from state[-3].\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": str(1)}}\n",
    "for state in graph.get_state_history(thread):\n",
    "    print(state,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272281e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Modify State Let's start by starting a fresh thread and running to clean out history.\n",
    "\n",
    "thread2 = {\"configurable\": {\"thread_id\": str(2)}}\n",
    "graph.invoke({\"count\":0, \"scratch\":\"hi\"},thread2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e01806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states2 = []\n",
    "for state in graph.get_state_history(thread2):\n",
    "    states2.append(state.config)\n",
    "    print(state.config, state.values['count'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9989a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Start by grabbing a state.\n",
    "save_state = graph.get_state(states2[-3])\n",
    "save_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now modify the values. One subtle item to note: Recall when agent state was defined, count used operator.add to indicate that values are added to the current value. Here, -3 will be added to the current count value rather than replace it.\n",
    "\n",
    "save_state.values[\"count\"] = -3\n",
    "save_state.values[\"scratch\"] = \"hello\"\n",
    "save_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8395f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now update the state. This creates a new entry at the top, or latest entry in memory. This will become the current state.\n",
    "\n",
    "graph.update_state(thread2,save_state.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Current state is at the top. You can match the thread_ts. Notice the parent_config, thread_ts of the new node - it is the previous node.\n",
    "\n",
    "for i, state in enumerate(graph.get_state_history(thread2)):\n",
    "    if i >= 3:  #print latest 3\n",
    "        break\n",
    "    print(state, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86919ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Try again with as_node When writing using update_state(), you want to define to the graph logic which node should be assumed as the writer. What this does is allow the graph logic to find the node on the graph. After writing the values, the next() value is computed by traversing the graph using the new state. In this case, the state we have was written by Node1. The graph can then compute the next state as being Node2. Note that in some graphs, this may involve going through conditional edges! Let's try this out.\n",
    "\n",
    "graph.update_state(thread2,save_state.values, as_node=\"Node1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c00816",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, state in enumerate(graph.get_state_history(thread2)):\n",
    "    if i >= 3:  #print latest 3\n",
    "        break\n",
    "    print(state, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4183064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke will run from the current state if not given a particular thread_ts. This is now the entry that was just added.\n",
    "\n",
    "graph.invoke(None,thread2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2db057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out the state history, notice the scratch value change on the latest entries.\n",
    "for state in graph.get_state_history(thread2):\n",
    "    print(state,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0291c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
